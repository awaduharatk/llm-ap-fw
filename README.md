# llm-ap-fw
LLMアプリケーションフレームワークを触ってみる

## 用語

### LLM (Large Language Model)
大規模言語モデルの略。  
大量のデータを基に学習し、人間の言語を理解したり生成したりできるAIモデルのこと。  
これにより、文章生成や翻訳、質問応答などのタスクをこなすことが可能。  
GPT-4などのこと。  

### プロンプト
LLMなどのAIモデルに対する指示や質問のこと。  
プロンプトに対して、モデルはそれに応じたテキストを生成したり、質問に回答する。  
プロンプトの工夫次第で、モデルが出力する結果の質や内容が変わる。  
このプロンプトの工夫でモデルの能力を引き出すための技術をプロンプトエンジニアリングと呼ぶ。  


### ファインチューニング
既に学習済みのAIモデルに対して、新しいデータを用いて追加の訓練を行うこと。  
これにより、特定のタスクや分野に特化したモデルを作ることができる。  


### コンテキストラーニング




#### GPTモデルのファインチューニング
GPTモデルはファインチューニング用のAPIが用意されている  
[OpenAI #fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)  
学習時のトークン数で課金、作成したモデルでも課金なので、結構お金がかかりそう？


## LLMアプリケーションフレームワークとは
LangChainなど、LLMを使用したアプリケーションを構築するためのフレームワーク。
GPTモデルにプロンプトを追加してラッピング、データベースから必要な情をくっつけてプロンプトするなどの実装ができるFW


### 種類
どんなFWがあるか調べてみた

| フレームワーク                | 特徴                             | 主な機能                                               | 向いている用途                                                                            | 使用可能なLLMと制限                                                                                            |
| ----------------------------- | -------------------------------- | ------------------------------------------------------ | ----------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |
| **LangChain**                 | LLMの拡張・外部ツール連携        | チェーン管理、エージェント、メモリ機能、外部データ接続 | 複雑なワークフローやマルチステップのLLMアプリケーション構築、カスタマイズ可能なボット開発 | オープンソースモデルやOpenAI、Anthropicなどの商用APIも利用可能。LLMの種類に柔軟だが、外部APIの利用には制限あり |
| **Hugging Face Transformers** | オープンソースLLMのライブラリ    | 多様なモデルサポート、微調整、分散学習                 | NLPタスク全般（文章生成、翻訳、要約など）、トレーニングと微調整が必要なプロジェクト       | ほぼすべてのHugging Faceモデル（BERT, GPT, T5など）をサポート。大規模モデルはリソース依存                      |
| **Rasa**                      | 対話型AIプラットフォーム         | インテント認識、エンティティ抽出、対話管理             | カスタマーサポートボット、FAQシステム、インタラクティブな対話システム                     | 内蔵モデルはないため、外部LLM（Hugging FaceやGPT系）との連携にはカスタム実装が必要                             |
| **Haystack (deepset.ai)**     | ドキュメント検索と質問応答に特化 | 検索、質問応答、ナレッジグラフの構築                   | 大規模なドキュメントベースの質問応答、企業内ナレッジマネジメント                          | Hugging Face Transformersや他のオープンソースLLMと連携可能。特定のフォーマットやAPIに依存                      |
| **Cohere**                    | コマンド型LLM                    | 高速な応答生成、指示理解に特化                         | 精度が求められる対話システム、ドキュメント検索                                            | Cohereの独自モデル（Commandなど）に限定され、APIの使用制限がある                                               |
| **LlamaIndex (GPT Index)**    | データ連携と検索機能に強み       | データベース、CSV、ウェブデータとの統合、質問応答      | データ駆動型のアプリケーション、複雑なデータセットに基づく質問応答                        | 主にオープンソースモデル（LLaMAなど）をサポート。特定のデータソースとの統合に制約あり                          |
| **Falcon-40B**                | 多言語対応のLLM                  | 高性能な自然言語処理、翻訳、要約                       | 翻訳、情報取得、マルチリンガルシステム                                                    | Falconモデル（1B, 7B, 40B）を使用。大規模なリソースが必要                                                      |
| **Claude 3**                  | 安全性に配慮したLLM              | 多言語対応、AI行動制御（Constitutional AI）            | セキュリティ重視の対話型アプリケーション、ビジネス向けのAIソリューション                  | Claude 3（Anthropic提供）のみ使用可能。API制限や使用量制限がある                                               |
| **Mistral 7B**                | 高効率な小型LLM                  | 少ないリソースで長文処理、高精度なテキスト生成         | コード生成、軽量なNLPアプリケーション、ローカルでの利用                                   | Mistralの7Bモデル（オープンソース）。軽量だが、対応言語や機能に制約あり                                        |



### チャットボット作成FW
- FlowiseAI
- Auto-GPT
- AgentGPT
- BabyAGI
- LangDock


### LangChain
- LangSmith



## プロンプティングか？ファインチューニングか？

| 項目                     | ファインチューニング                                       | プロンプトエンジニアリング（LangChain）                      |
| ------------------------ | ---------------------------------------------------------- | ------------------------------------------------------------ |
| **適したタスク**         | 高精度が必要な特定ドメインのタスク（医療、法務など）       | 幅広いタスク、柔軟な応答や多様な要求に対応するタスク         |
| **文体やトーンの一貫性** | 特定のトーンや文体にモデルを最適化可能                     | プロンプトでカスタマイズするが、一貫性の確保は難しい         |
| **専門的な知識**         | 専門知識を学習したモデルが必要な場合に有効                 | 専門知識をプロンプトで指定するが、特化モデルほど正確ではない |
| **応答の正確性**         | 非常に高い正確性（データに依存）                           | 柔軟だが、モデル自体の能力に依存するため精度は相対的に低い   |
| **コストと時間**         | トレーニングには高いコストと時間がかかる                   | 迅速に実装可能でコストが低い                                 |
| **柔軟性**               | 一度トレーニングすると変更が難しい                         | プロンプトを簡単に変更可能                                   |
| **タスクの変更頻度**     | 長期的・安定的なタスクに向いている                         | 頻繁にタスクが変わる場合に有効                               |
| **初期開発・実験**       | 初期段階のプロジェクトには不向き（コストや時間の観点から） | プロジェクトの初期段階や実験に適している                     |
| **多言語対応**           | 特定の言語に特化して最適化可能                             | 汎用モデルにプロンプトで指示可能だが、一部言語で限界がある   |
| **使用例**               | カスタマーサポート、医療系アプリケーション                 | チャットボット、FAQボット、プロトタイプの開発                |


